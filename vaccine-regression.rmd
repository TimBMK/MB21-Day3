---
title: "Covid vaccine regression"
author: ""
date: "03/08/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
```

## Regression problem

- We will run regression and other related models for Covid-19 vaccination data

## Libiraries

- We will use the following packages

```{r}
library(tidyverse)
library(caret)
library(glmnet)
```

## Load data

We will use the following data. It is a combined dataset from three data sources we have been using. The code for processing is available at `data_prep/data_preparation.R`.

```{r}
data_vac <- read_csv("data/vaccine-data.csv.gz") 
```


## Check data

Let's have a cursory look at the data, especially check the distribution of the output variable `Booster_Doses_18Plus_Vax_Pct` Do we need conversion?

### `head()`

```{r}
data_vac %>% head()
```

### Check the distribution of the output

```{r}
data_vac %>%
  ggplot(aes(x = Booster_Doses_18Plus_Vax_Pct)) +
  geom_density()
```

```{r}

```


## Decide the variable to include as input

- There are 47 variables what are possible predictors? Especially:
  - trump_pct
  - demography: TotalPop, Men, Women, Hispanic, White, Black, Native, Asian, Pacific, VotingAgeCitizen, Income, IncomePerCap, Poverty, ChildPoverty, Professional, Service, Office, Construction, Production, Drive, Carpool, Transit, Walk, OtherTransp, WorkAtHome, MeanCommute, Employed, PrivateWork, PublicWork, SelfEmployed, FamilyWork, Unemployment
- What do you think should be included as the inputs?


```{r}
names(data_vac)

data_vac_use <- data_vac %>%
  select(Booster_Doses_18Plus_Vax_Pct, Black, Hispanic, IncomePerCap, Poverty, ChildPoverty, Unemployment, pct_trump) %>% 
  drop_na()
```

## Data preparation

Here we need to prepare the data, in particular:

1. Train-test split
2. Data preprocessing

Using `caret` (or something else if you like), prepare two datasets of pre-processed train/test data.

## Train-test split

```{r}
set.seed(20220804) # set seed for reproducability (e.g. today's date...)

train_id <- createDataPartition(
  data_vac_use$Booster_Doses_18Plus_Vax_Pct,
  times = 1,
  p = 0.7,
  list = F
)

df_train <- data_vac_use %>% 
  slice(train_id) # slice over index provided by train_id

df_test <- data_vac_use %>% 
  slice(-train_id)
```

## Preprocess

```{r}
prep <- df_train %>% select(-Booster_Doses_18Plus_Vax_Pct) %>% # the dependant variable (and any dummy variables) should not be included in the preprocessing
  preProcess(method = c("center", "scale"))

df_train_prepped <- df_train %>% predict(prep, .)

df_test_prepped <- df_test %>% predict(prep, .)

```


## Analysis

### Linear regression

- Run linear regression 
- Evaluate the model

```{r}
model_lm <- lm(Booster_Doses_18Plus_Vax_Pct ~ ., data = df_train_prepped)
summary(model_lm)

```
```{r}
rmse <- function(errors){
  return((errors^2) %>% mean() %>% sqrt())
}

pred_train <- predict(model_lm)
error_train <- pred_train - df_train_prepped$Booster_Doses_18Plus_Vax_Pct
rmse(error_train)


pred_test <- predict(model_lm, newdata = df_test_prepped)
error_test <- pred_test - df_test_prepped$Booster_Doses_18Plus_Vax_Pct
rmse(error_test)
```

### Additional model evaluations

Using the linear regression model as the baseline we attempt two things:

1. Is it possible to improve the prediction using more flexible models?
  - KNN-regression
  - Or regression model variant of models covered in classificaiton section. 
    - For example:
      - svm: svmPoly, svmRadial works both regression and classification (svmPoly may take quite long time as the number of tuning paramters are many.)
      - trees: rf
      


```{r}
ctrl <- trainControl(method = "repeatedcv", repeats = 10, number = 5)

model_knn <- train(Booster_Doses_18Plus_Vax_Pct ~ ., 
                   method = "knn",
                   data = df_train_prepped, trControl = ctrl)

model_knn # caret automatically chooses candidate values for k, but can be set by hand with tuneGrid

train(Booster_Doses_18Plus_Vax_Pct ~ ., 
      method = "knn",
      data = df_train_prepped, trControl = ctrl,
      tuneGrid = data.frame(k = c(1:10, 20, 30))) # tuneGrid (here for k values) needs to be a data.frame

pred_train <- predict(model_knn)
error_train <- pred_train - df_train_prepped$Booster_Doses_18Plus_Vax_Pct
rmse(error_train)


pred_test <- predict(model_knn, newdata = df_test_prepped)
error_test <- pred_test - df_test_prepped$Booster_Doses_18Plus_Vax_Pct
rmse(error_test) 

# we can see that the RMSE improved with the KNN method

```


### SVM with Radial Kernel

```{r}


```


## LASSO and ridge regression

- Now, let's run LASSO and/or Ridge regression. 
- What do you find? 
  - Shrinkage of the coefficients

### LASSO Outcome

```{r}
mat_train_x <- df_train_prepped %>% select(-Booster_Doses_18Plus_Vax_Pct) %>% as.matrix() #glmnet requires a matrix as input
mat_test_x <- df_test_prepped %>% select(-Booster_Doses_18Plus_Vax_Pct) %>% as.matrix() 

model_lasso <- cv.glmnet(mat_train_x, 
                         df_train_prepped$Booster_Doses_18Plus_Vax_Pct, #output variable
                         alpha = 1, # 1 for lasso, if alpha = 0 this runs ridge regression
                         type.measure = "mse",
                         family = "gaussian") # family argument is required for glm functions

coef(model_lasso) # glmnet chooses final lambda (and therefore nr of variables) based on increase in RMSE against best model
plot(model_lasso)
plot(model_lasso$glmnet.fit, xvar = "lambda")

pred_train <- predict(model_lasso, newx = mat_train_x)
error_train <- pred_train - df_train_prepped$Booster_Doses_18Plus_Vax_Pct
rmse(error_train)

pred_test <- predict(model_lasso, newx = mat_test_x)
error_test <- pred_test - df_test_prepped$Booster_Doses_18Plus_Vax_Pct
rmse(error_test)


```

#### Plot with `plot_glmnet`

Shrinkage plot of `glmnet` is not informative as it won't show the variable name. Instead you can use `plot_glmnet` in `plotmo` package.

```{r}
plotmo::plot_glmnet(model_lasso$glmnet.fit, xvar = "lambda")
```



### Ridge regression outcome

```{r}

```

#### Plot with `plot_glmnet`

```{r}

```

### Compare coefs: lm, lasso/ridge

Compare the cefficients across the models. What do you find?

```{r}

```